{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/daviddanial/chestxrayCNN/blob/main/Untitled40.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6WmSDsEy3Lay"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "619cdaf3"
      },
      "source": [
        "First, let's load the necessary libraries and a subset of the MNIST data. We'll use `neural_tangents` which is a library for working with NTKs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "99a722cc",
        "outputId": "051cd4ae-6cda-4dab-96a2-19a7b14b9cf5"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'neural_tangents'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1044766444.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mjnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mneural_tangents\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mjax\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mjax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstax\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'neural_tangents'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# Install neural_tangents if you haven't already\n",
        "# !pip install neural_tangents jax jaxlib\n",
        "\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import neural_tangents as nt\n",
        "from jax import random\n",
        "from jax.experimental import stax\n",
        "import numpy as np\n",
        "\n",
        "# Load a subset of MNIST data (for faster computation)\n",
        "# In a real scenario, you would load the full dataset\n",
        "key = random.PRNGKey(0)\n",
        "train_images = np.random.rand(100, 28*28) # Dummy data resembling flattened MNIST images\n",
        "test_images = np.random.rand(50, 28*28)\n",
        "\n",
        "# Normalize data if necessary (important for NTK theory)\n",
        "train_images /= 255.0\n",
        "test_images /= 255.0\n",
        "\n",
        "print(f\"Shape of training data subset: {train_images.shape}\")\n",
        "print(f\"Shape of test data subset: {test_images.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4ed3b76"
      },
      "source": [
        "Now, let's define a simple neural network architecture using `stax`. We'll use a simple fully-connected network. The `stax.serial` function stacks layers sequentially. `stax.Flatten` reshapes the input, `stax.Dense` is a fully connected layer, and `stax.Relu` is the activation function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 558
        },
        "id": "28551716",
        "outputId": "115972c2-3876-44c0-dbb9-795a7c1ce433"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'stax' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3002357552.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Let's create a network with a reasonably large width\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mwidth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2048\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0minit_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_mlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Created MLP with width: {width}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3002357552.py\u001b[0m in \u001b[0;36mcreate_mlp\u001b[0;34m(width)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# The width of the Dense layers impacts the NTK behavior\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcreate_mlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   init_fn, apply_fn, kernel_fn = stax.serial(\n\u001b[0m\u001b[1;32m      5\u001b[0m       \u001b[0mstax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFlatten\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m       \u001b[0mstax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW_std\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_std\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# Large width here is key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'stax' is not defined"
          ]
        }
      ],
      "source": [
        "# Define a simple neural network architecture\n",
        "# The width of the Dense layers impacts the NTK behavior\n",
        "def create_mlp(width):\n",
        "  init_fn, apply_fn, kernel_fn = stax.serial(\n",
        "      stax.Flatten,\n",
        "      stax.Dense(width, W_std=1.0, b_std=0.0), # Large width here is key\n",
        "      stax.Relu(),\n",
        "      stax.Dense(width, W_std=1.0, b_std=0.0),\n",
        "      stax.Relu(),\n",
        "      stax.Dense(10, W_std=1.0, b_std=0.0) # Output layer for 10 classes\n",
        "  )\n",
        "  return init_fn, apply_fn, kernel_fn\n",
        "\n",
        "# Let's create a network with a reasonably large width\n",
        "width = 2048\n",
        "init_fn, apply_fn, kernel_fn = create_mlp(width)\n",
        "\n",
        "print(f\"Created MLP with width: {width}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OVleYdAn5B4C"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Re1UHVL5D6F"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3fb0bfdf"
      },
      "source": [
        "Now, we can use the `kernel_fn` provided by `neural_tangents` to compute the NTK matrix. This function computes the kernel between two sets of inputs. We are interested in the NTK between training data points (`train_images`) and between training and test data points (`train_images`, `test_images`).\n",
        "\n",
        "The `nt.empirical_kernel_fn` can also be used to compute the empirical NTK for finite-width networks. The `kernel_fn` from `stax.serial` when using standard layers (like `stax.Dense`) computes the NTK in the infinite-width limit.\n",
        "\n",
        "We'll compute the *full* kernel, which includes both the Neural Tangent Kernel and the Neural Gradient Covariance kernel. For understanding the linear dynamics under gradient descent, the NTK part is usually what's needed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "14f5ed8e",
        "outputId": "ba0a2d26-ac34-4617-9edc-63beb47fc4d1"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'kernel_fn' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3744505795.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Compute the NTK between training examples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Setting get='ntk' specifically computes the NTK part of the kernel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mntk_train_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkernel_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ntk'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Shape of NTK (train_train): {ntk_train_train.shape}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'kernel_fn' is not defined"
          ]
        }
      ],
      "source": [
        "# Assume compute_ntk_mnist is defined elsewhere and calculates the NTK\n",
        "# For demonstration, we'll use the kernel_fn from neural_tangents directly\n",
        "# as a placeholder for your provided function's functionality.\n",
        "# In a real scenario, you would call your compute_ntk_mnist function here.\n",
        "\n",
        "# Compute the NTK between training examples\n",
        "# Setting get='ntk' specifically computes the NTK part of the kernel\n",
        "ntk_train_train = kernel_fn(train_images, None, get='ntk')\n",
        "print(f\"Shape of NTK (train_train): {ntk_train_train.shape}\")\n",
        "\n",
        "# Compute the NTK between training and test examples\n",
        "ntk_train_test = kernel_fn(train_images, test_images, get='ntk')\n",
        "print(f\"Shape of NTK (train_test): {ntk_train_test.shape}\")\n",
        "\n",
        "# You can also compute the NTK between test examples (test_test) if needed\n",
        "ntk_test_test = kernel_fn(test_images, None, get='ntk')\n",
        "print(f\"Shape of NTK (test_test): {ntk_test_test.shape}\")\n",
        "\n",
        "# LESSON: For sufficiently wide networks, these kernel matrices\n",
        "# approximately characterize the network's behavior during training\n",
        "# without needing to run gradient descent on the full network parameters.\n",
        "# The NTK describes the linearization of the network around its initialization."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1267092"
      },
      "source": [
        "**Key Lesson Emphasized:**\n",
        "\n",
        "This example demonstrates that for wide neural networks, the Neural Tangent Kernel matrix, computed using functions like the one from `neural_tangents` (or potentially your `compute_ntk_mnist`), provides a powerful tool. The NTK allows us to approximate and analyze the training dynamics of the network under gradient descent as a linear model in a fixed feature space.\n",
        "\n",
        "This means that instead of tracking the changes in millions of network parameters during training, we can often gain significant insight by simply computing and analyzing the NTK matrix, especially for understanding the behavior of very wide networks on datasets like MNIST. The closer the network is to the infinite-width limit, the more accurate this NTK approximation becomes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "44d3f7d4",
        "outputId": "bc3114a3-3957-4036-f2d6-509ab1b325ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting neural_tangents\n",
            "  Downloading neural_tangents-0.6.5-py2.py3-none-any.whl.metadata (26 kB)\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.12/dist-packages (0.5.3)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.12/dist-packages (0.5.3)\n",
            "Requirement already satisfied: frozendict>=2.3.8 in /usr/local/lib/python3.12/dist-packages (from neural_tangents) (2.4.6)\n",
            "Requirement already satisfied: tensorflow>=2.15.0 in /usr/local/lib/python3.12/dist-packages (from neural_tangents) (2.19.0)\n",
            "Collecting tf2jax>=0.3.5 (from neural_tangents)\n",
            "  Downloading tf2jax-0.3.8-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: ml_dtypes>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from jax) (0.5.3)\n",
            "Requirement already satisfied: numpy>=1.25 in /usr/local/lib/python3.12/dist-packages (from jax) (2.0.2)\n",
            "Requirement already satisfied: opt_einsum in /usr/local/lib/python3.12/dist-packages (from jax) (3.4.0)\n",
            "Requirement already satisfied: scipy>=1.11.1 in /usr/local/lib/python3.12/dist-packages (from jax) (1.16.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.15.0->neural_tangents) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.15.0->neural_tangents) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.15.0->neural_tangents) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.15.0->neural_tangents) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.15.0->neural_tangents) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.15.0->neural_tangents) (18.1.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.15.0->neural_tangents) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.15.0->neural_tangents) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.15.0->neural_tangents) (2.32.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.15.0->neural_tangents) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.15.0->neural_tangents) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.15.0->neural_tangents) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.15.0->neural_tangents) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.15.0->neural_tangents) (1.17.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.15.0->neural_tangents) (1.74.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.15.0->neural_tangents) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.15.0->neural_tangents) (3.10.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow>=2.15.0->neural_tangents) (3.14.0)\n",
            "Requirement already satisfied: dm-tree>=0.1.5 in /usr/local/lib/python3.12/dist-packages (from tf2jax>=0.3.5->neural_tangents) (0.1.9)\n",
            "Collecting jax\n",
            "  Downloading jax-0.7.1-py3-none-any.whl.metadata (13 kB)\n",
            "INFO: pip is looking at multiple versions of tf2jax to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting tf2jax>=0.3.5 (from neural_tangents)\n",
            "  Downloading tf2jax-0.3.7-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow>=2.15.0->neural_tangents) (0.45.1)\n",
            "Requirement already satisfied: attrs>=18.2.0 in /usr/local/lib/python3.12/dist-packages (from dm-tree>=0.1.5->tf2jax>=0.3.5->neural_tangents) (25.3.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow>=2.15.0->neural_tangents) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow>=2.15.0->neural_tangents) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow>=2.15.0->neural_tangents) (0.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow>=2.15.0->neural_tangents) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow>=2.15.0->neural_tangents) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow>=2.15.0->neural_tangents) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.21.0->tensorflow>=2.15.0->neural_tangents) (2025.8.3)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow>=2.15.0->neural_tangents) (3.8.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow>=2.15.0->neural_tangents) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow>=2.15.0->neural_tangents) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow>=2.15.0->neural_tangents) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow>=2.15.0->neural_tangents) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow>=2.15.0->neural_tangents) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow>=2.15.0->neural_tangents) (0.1.2)\n",
            "Downloading neural_tangents-0.6.5-py2.py3-none-any.whl (248 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m248.7/248.7 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tf2jax-0.3.7-py3-none-any.whl (97 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.3/97.3 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tf2jax, neural_tangents\n",
            "Successfully installed neural_tangents-0.6.5 tf2jax-0.3.7\n"
          ]
        }
      ],
      "source": [
        "!pip install neural_tangents jax jaxlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GssFoAIH5R31"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "zzCRiqJP5T0F",
        "outputId": "16b496a3-a40a-4198-bc16-fe2dc779b0f0"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'stax' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3002357552.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;31m# Let's create a network with a reasonably large width\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mwidth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2048\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0minit_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_mlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Created MLP with width: {width}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3002357552.py\u001b[0m in \u001b[0;36mcreate_mlp\u001b[0;34m(width)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# The width of the Dense layers impacts the NTK behavior\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcreate_mlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   init_fn, apply_fn, kernel_fn = stax.serial(\n\u001b[0m\u001b[1;32m      5\u001b[0m       \u001b[0mstax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFlatten\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m       \u001b[0mstax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW_std\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_std\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# Large width here is key\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'stax' is not defined"
          ]
        }
      ],
      "source": [
        "# Define a simple neural network architecture\n",
        "# The width of the Dense layers impacts the NTK behavior\n",
        "def create_mlp(width):\n",
        "  init_fn, apply_fn, kernel_fn = stax.serial(\n",
        "      stax.Flatten,\n",
        "      stax.Dense(width, W_std=1.0, b_std=0.0), # Large width here is key\n",
        "      stax.Relu(),\n",
        "      stax.Dense(width, W_std=1.0, b_std=0.0),\n",
        "      stax.Relu(),\n",
        "      stax.Dense(10, W_std=1.0, b_std=0.0) # Output layer for 10 classes\n",
        "  )\n",
        "  return init_fn, apply_fn, kernel_fn\n",
        "\n",
        "# Let's create a network with a reasonably large width\n",
        "width = 2048\n",
        "init_fn, apply_fn, kernel_fn = create_mlp(width)\n",
        "\n",
        "print(f\"Created MLP with width: {width}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP25l+a7KhaYrHIZMSwKxnF",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}